{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./cropped_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./cropped_images/chris_evans',\n",
       " './cropped_images/chris_hemsworth',\n",
       " './cropped_images/mark_ruffalo',\n",
       " './cropped_images/robert_downey_jr',\n",
       " './cropped_images/scarlett_johansson']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)\n",
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chris_evans\n",
      "chris_hemsworth\n",
      "mark_ruffalo\n",
      "robert_downey_jr\n",
      "scarlett_johansson\n"
     ]
    }
   ],
   "source": [
    "celebrity_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    print(celebrity_name)\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    \n",
    "    for entry in os.scandir(img_dir):\n",
    "        celebrity_file_names_dict[celebrity_name].append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chris_evans': 0,\n",
       " 'chris_hemsworth': 1,\n",
       " 'mark_ruffalo': 2,\n",
       " 'robert_downey_jr': 3,\n",
       " 'scarlett_johansson': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        scalled_raw_img = cv2.resize(img, (img_height, img_width))\n",
    "#         img_har = w2d(img,'db1',5)\n",
    "#         scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "#         combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(scalled_raw_img)\n",
    "        y.append(class_dict[celebrity_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 180, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 180, 180, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =keras.Sequential([\n",
    "  keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dense(5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 180, 180, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 90, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               3965056   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,989,285\n",
      "Trainable params: 3,989,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 6.4896 - accuracy: 0.2678\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 6.1724 - accuracy: 0.2069\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 6.2662 - accuracy: 0.2470\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 6.1190 - accuracy: 0.2794\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 6.0633 - accuracy: 0.2537\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 5.7179 - accuracy: 0.1955\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 5.8810 - accuracy: 0.2101\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 5.9615 - accuracy: 0.2473\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 5.3815 - accuracy: 0.2783\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 105ms/step - loss: 6.3702 - accuracy: 0.2209\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "7/7 [==============================] - 5s 366ms/step - loss: 3.3153 - accuracy: 0.2538\n",
      "Epoch 2/40\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 1.6105 - accuracy: 0.1988\n",
      "Epoch 3/40\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 1.5562 - accuracy: 0.2479\n",
      "Epoch 4/40\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 1.4120 - accuracy: 0.4529\n",
      "Epoch 5/40\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 1.1070 - accuracy: 0.6609\n",
      "Epoch 6/40\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.7565 - accuracy: 0.7534\n",
      "Epoch 7/40\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.6675 - accuracy: 0.8004\n",
      "Epoch 8/40\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5133 - accuracy: 0.8491\n",
      "Epoch 9/40\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.2790 - accuracy: 0.8931\n",
      "Epoch 10/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.2167 - accuracy: 0.9469\n",
      "Epoch 11/40\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.1283 - accuracy: 0.9582\n",
      "Epoch 12/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0651 - accuracy: 0.9866\n",
      "Epoch 13/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 14/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.0336 - accuracy: 0.9951\n",
      "Epoch 16/40\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.0635 - accuracy: 0.9862\n",
      "Epoch 17/40\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.0510 - accuracy: 0.9784\n",
      "Epoch 18/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0359 - accuracy: 0.9973\n",
      "Epoch 19/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 22/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 23/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 9.6600e-04 - accuracy: 1.00000s - loss: 8.9702e-04 - accura\n",
      "Epoch 24/40\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 7.5756e-04 - accuracy: 1.0000\n",
      "Epoch 25/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 7.4388e-04 - accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 6.0106e-04 - accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 4.1957e-04 - accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 4.3909e-04 - accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 4.9912e-04 - accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 3.6763e-04 - accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 2.6429e-04 - accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 2.5285e-04 - accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 3.0079e-04 - accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 2.8257e-04 - accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 2.6071e-04 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 2.6293e-04 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 2.3692e-04 - accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 2.2043e-04 - accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 1.8700e-04 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 1.6094e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28109d3bd60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = keras.Sequential(\n",
    "[\n",
    "    # cnn\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(img_height,img_height,3)),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Dense\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128 ,activation='relu'),\n",
    "       \n",
    "    keras.layers.Dense(5,  activation='softmax')\n",
    "])\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction=\"auto\", name=\"sparse_categorical_crossentropy\"\n",
    ")\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "cnn.fit(X_train, y_train, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 328ms/step - loss: 1.4799 - accuracy: 0.7681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4799182415008545, 0.7681159377098083]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(x=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clsses = [np.argmax(e) for e in y_pred]\n",
    "y_clsses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
